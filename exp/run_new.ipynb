{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7545a6b-c7b0-46e1-9a31-c10656345262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: comet_ml in /home/jovyan/.local/lib/python3.11/site-packages (3.49.7)\n",
      "Requirement already satisfied: cartopy in /home/jovyan/.local/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: h5netcdf in /home/jovyan/.local/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: netcdf4 in /home/jovyan/.local/lib/python3.11/site-packages (1.6.4)\n",
      "Requirement already satisfied: scipy in /home/jovyan/.local/lib/python3.11/site-packages (1.11.1)\n",
      "Requirement already satisfied: einops in /home/jovyan/.local/lib/python3.11/site-packages (0.6.1)\n",
      "Requirement already satisfied: torchdiffeq in /home/jovyan/.local/lib/python3.11/site-packages (0.2.5)\n",
      "Requirement already satisfied: torchsummary in /home/jovyan/.local/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (0.22.8)\n",
      "Requirement already satisfied: everett[ini]<3.2.0,>=1.0.1 in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (3.1.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /opt/conda/lib/python3.11/site-packages (from comet_ml) (4.17.3)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (5.9.5)\n",
      "Requirement already satisfied: python-box<7.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from comet_ml) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (2.28.2)\n",
      "Requirement already satisfied: rich>=13.3.2 in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (13.4.2)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (1.30.0)\n",
      "Requirement already satisfied: simplejson in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (3.20.1)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/jovyan/.local/lib/python3.11/site-packages (from comet_ml) (1.26.13)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /opt/conda/lib/python3.11/site-packages (from comet_ml) (1.14.1)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /opt/conda/lib/python3.11/site-packages (from comet_ml) (3.0.2)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/jovyan/.local/lib/python3.11/site-packages (from cartopy) (1.24.1)\n",
      "Requirement already satisfied: matplotlib>=3.4 in /home/jovyan/.local/lib/python3.11/site-packages (from cartopy) (3.7.2)\n",
      "Requirement already satisfied: shapely>=1.7 in /home/jovyan/.local/lib/python3.11/site-packages (from cartopy) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20 in /home/jovyan/.local/lib/python3.11/site-packages (from cartopy) (23.1)\n",
      "Requirement already satisfied: pyshp>=2.1 in /home/jovyan/.local/lib/python3.11/site-packages (from cartopy) (2.3.1)\n",
      "Requirement already satisfied: pyproj>=3.1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from cartopy) (3.6.1)\n",
      "Requirement already satisfied: h5py in /home/jovyan/.local/lib/python3.11/site-packages (from h5netcdf) (3.12.1)\n",
      "Requirement already satisfied: cftime in /home/jovyan/.local/lib/python3.11/site-packages (from netcdf4) (1.6.2)\n",
      "Requirement already satisfied: certifi in /home/jovyan/.local/lib/python3.11/site-packages (from netcdf4) (2022.12.7)\n",
      "Requirement already satisfied: torch>=1.5.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torchdiffeq) (2.0.1+cu118)\n",
      "Requirement already satisfied: configobj in /home/jovyan/.local/lib/python3.11/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (5.0.9)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.18.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jovyan/.local/lib/python3.11/site-packages (from matplotlib>=3.4->cartopy) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->cartopy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jovyan/.local/lib/python3.11/site-packages (from matplotlib>=3.4->cartopy) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->cartopy) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jovyan/.local/lib/python3.11/site-packages (from matplotlib>=3.4->cartopy) (9.3.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->cartopy) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.4->cartopy) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jovyan/.local/lib/python3.11/site-packages (from requests>=2.18.4->comet_ml) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.18.4->comet_ml) (3.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jovyan/.local/lib/python3.11/site-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=13.3.2->comet_ml) (2.15.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.5.0->torchdiffeq) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=1.5.0->torchdiffeq) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.5.0->torchdiffeq) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=1.5.0->torchdiffeq) (3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.5.0->torchdiffeq) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/jovyan/.local/lib/python3.11/site-packages (from torch>=1.5.0->torchdiffeq) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/jovyan/.local/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.5.0->torchdiffeq) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/jovyan/.local/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.5.0->torchdiffeq) (15.0.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jovyan/.local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.4->cartopy) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jovyan/.local/lib/python3.11/site-packages (from jinja2->torch>=1.5.0->torchdiffeq) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jovyan/.local/lib/python3.11/site-packages (from sympy->torch>=1.5.0->torchdiffeq) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install comet_ml cartopy h5netcdf netcdf4 scipy einops torchdiffeq torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c72d78-bd3c-4748-bce1-09d1d3cb29f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4pdvGPU Msg(3794:140099667196800:libvgpu.c:869)]: Initializing.....\n",
      "[4pdvGPU Warn(3794:140099667196800:hook.c:475)]: remap handles for device 0\n",
      "[4pdvGPU Warn(3794:140099667196800:multiprocess_memory_limit.c:568)]: Kick dead proc 3512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset,ConcatDataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import xarray as xr\n",
    "from dataset import *\n",
    "from train import Trainer  \n",
    "from PIL import Image\n",
    "from comet_ml import Experiment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "import sys\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "sys.path.append('/home/jovyan/work/spatial-temporal/models/graph_grid_model')\n",
    "logger.add(\"./logs/training_log.log\", rotation=\"1 MB\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca59a3a-8734-4a5a-824a-22213d9da026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35064 time steps for input variables ['2m_temperature'] and target variables ['2m_temperature'] with step 1. Total input channels: 1, Total target channels: 1.\n",
      "Loaded 4344 time steps for input variables ['2m_temperature'] and target variables ['2m_temperature'] with step 1. Total input channels: 1, Total target channels: 1.\n",
      "Loaded 4416 time steps for input variables ['2m_temperature'] and target variables ['2m_temperature'] with step 1. Total input channels: 1, Total target channels: 1.\n",
      "Generating timestamps...\n",
      "Timestamps generated: 35041 points.\n",
      "Loading and filtering station data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:30<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Generating timestamps...\n",
      "Timestamps generated: 4321 points.\n",
      "Loading and filtering station data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:28<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Generating timestamps...\n",
      "Timestamps generated: 4393 points.\n",
      "Loading and filtering station data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:28<00:00, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_slice_train = (\"2014-01-01\", \"2017-12-31\")  # 加载指定时间范围的数据\n",
    "time_slice_val = ('2018-01-01', '2018-6-30') # 加载指定时间范围的数据\n",
    "time_slice_test = ('2018-07-01', '2018-12-31')  # 加载指定时间范围的数据\n",
    "# time_slice_train = (\"2014-01-01\", \"2014-01-10\")  # 加载指定时间范围的数据\n",
    "# time_slice_val = (\"2014-01-11\", \"2014-01-17\") # 加载指定时间范围的数据\n",
    "# time_slice_test = (\"2014-01-14\", \"2014-01-22\")  # 加载指定时间范围的数据\n",
    "# variables for grid  weatherbench\n",
    "grid_root_dir = '/home/jovyan/work/data/all_1.40625deg/2m_temperature/media/rasp/Elements/weather-benchmark/1.40625deg'\n",
    "grid_variables = [\"2m_temperature\"]  # 如果为 None 则加载所有变量\n",
    "grid_step = 1  # 每隔 6 个时间步加载一个数据\n",
    "grid_time_window = 6\n",
    "grid_pred_window = 6\n",
    "\n",
    "\n",
    "# variables for graph  weather-5k\n",
    "# graph_root_dir = '/home/jovyan/work/data/WEATHER-5K/global_weather_stations'\n",
    "graph_root_dir = '/home/jovyan/work/data/WEATHER-5K/global_weather_stations_test'\n",
    "graph_variables = ['TMP']\n",
    "graph_step = 6\n",
    "graph_time_window = 6\n",
    "graph_pred_window = 6\n",
    "\n",
    "\n",
    "grid_dataset_train = WeatherBenchDataset(grid_root_dir,\n",
    "                                   input_variables=grid_variables,\n",
    "                                   target_variables=grid_variables,\n",
    "                                   time_window = grid_time_window,\n",
    "                                   pred_window=grid_pred_window,\n",
    "                                   time_slice=time_slice_train,\n",
    "                                   step=grid_step,\n",
    "                                   transform=None,\n",
    "                                   )\n",
    "grid_dataset_val = WeatherBenchDataset(grid_root_dir,\n",
    "                                   input_variables=grid_variables,\n",
    "                                   target_variables=grid_variables,\n",
    "                                   time_window = grid_time_window,\n",
    "                                   pred_window=grid_pred_window,\n",
    "                                   time_slice=time_slice_val,\n",
    "                                   step=grid_step,\n",
    "                                   transform=None,)\n",
    "grid_dataset_test = WeatherBenchDataset(grid_root_dir,\n",
    "                                   input_variables=grid_variables,\n",
    "                                   target_variables=grid_variables,\n",
    "                                   time_window = grid_time_window,\n",
    "                                   pred_window=grid_pred_window,\n",
    "                                   time_slice=time_slice_test,\n",
    "                                   step=grid_step,\n",
    "                                   transform=None,)\n",
    "\n",
    "\n",
    "graph_dataset_train = Weather5kDataset(root_dir=graph_root_dir, \n",
    "                                 variables=graph_variables, \n",
    "                                 time_window=graph_time_window, \n",
    "                                 pred_window=graph_pred_window, \n",
    "                                 time_slice=time_slice_train, \n",
    "                                 step=graph_step,\n",
    "                                 target_variables=['TMP'])\n",
    "graph_dataset_val = Weather5kDataset(root_dir=graph_root_dir, \n",
    "                                 variables=graph_variables, \n",
    "                                 time_window=graph_time_window, \n",
    "                                 pred_window=graph_pred_window, \n",
    "                                 time_slice=time_slice_val, \n",
    "                                 step=graph_step,\n",
    "                                 target_variables=['TMP'])\n",
    "graph_dataset_test = Weather5kDataset(root_dir=graph_root_dir, \n",
    "                                 variables=graph_variables, \n",
    "                                 time_window=graph_time_window, \n",
    "                                 pred_window=graph_pred_window, \n",
    "                                 time_slice=time_slice_test, \n",
    "                                 step=graph_step,\n",
    "                                 target_variables=['TMP'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7bd5722-7d44-4a18-9983-02db7e7d8fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5830\n",
      "torch.Size([6, 1, 128, 256])\n",
      "torch.Size([6, 351, 1])\n"
     ]
    }
   ],
   "source": [
    "print(grid_dataset_train.__len__())\n",
    "y = grid_dataset_train[1]\n",
    "for j in y:\n",
    "    print(j.shape)\n",
    "    # print(j)\n",
    "    break\n",
    "\n",
    "x = graph_dataset_train[1]\n",
    "for i in x:\n",
    "    print(i.shape)\n",
    "    # print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd789e85-f9eb-41b2-9554-e8429a9891b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8731, 0.5811],\n",
      "         [0.8850, 0.5448],\n",
      "         [0.8893, 0.5829],\n",
      "         ...,\n",
      "         [0.7833, 0.5141],\n",
      "         [0.7789, 0.5146],\n",
      "         [0.7780, 0.5150]],\n",
      "\n",
      "        [[0.8731, 0.5811],\n",
      "         [0.8850, 0.5448],\n",
      "         [0.8893, 0.5829],\n",
      "         ...,\n",
      "         [0.7833, 0.5141],\n",
      "         [0.7789, 0.5146],\n",
      "         [0.7780, 0.5150]],\n",
      "\n",
      "        [[0.8731, 0.5811],\n",
      "         [0.8850, 0.5448],\n",
      "         [0.8893, 0.5829],\n",
      "         ...,\n",
      "         [0.7833, 0.5141],\n",
      "         [0.7789, 0.5146],\n",
      "         [0.7780, 0.5150]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.8731, 0.5811],\n",
      "         [0.8850, 0.5448],\n",
      "         [0.8893, 0.5829],\n",
      "         ...,\n",
      "         [0.7833, 0.5141],\n",
      "         [0.7789, 0.5146],\n",
      "         [0.7780, 0.5150]],\n",
      "\n",
      "        [[0.8731, 0.5811],\n",
      "         [0.8850, 0.5448],\n",
      "         [0.8893, 0.5829],\n",
      "         ...,\n",
      "         [0.7833, 0.5141],\n",
      "         [0.7789, 0.5146],\n",
      "         [0.7780, 0.5150]],\n",
      "\n",
      "        [[0.8731, 0.5811],\n",
      "         [0.8850, 0.5448],\n",
      "         [0.8893, 0.5829],\n",
      "         ...,\n",
      "         [0.7833, 0.5141],\n",
      "         [0.7789, 0.5146],\n",
      "         [0.7780, 0.5150]]])\n",
      "torch.Size([12, 6, 351, 1])\n",
      "torch.Size([12, 6, 351, 1])\n",
      "torch.Size([12, 6, 1, 128, 256])\n",
      "torch.Size([12, 6, 1, 128, 256])\n",
      "torch.Size([12, 6])\n",
      "torch.Size([12, 6, 351])\n",
      "torch.Size([12, 351, 2])\n"
     ]
    }
   ],
   "source": [
    "graph_grid_dataset_train = GridGraphDataset(grid_dataset_train, graph_dataset_train, grid_step, graph_step)\n",
    "graph_grid_dataset_val = GridGraphDataset(grid_dataset_val, graph_dataset_val, grid_step, graph_step)\n",
    "graph_grid_dataset_test = GridGraphDataset(grid_dataset_test, graph_dataset_test, grid_step, graph_step)\n",
    "# graph_grid_dataset_train = GridGraphDataset(grid_dataset_train, graph_dataset_train)\n",
    "# graph_grid_dataset_val = GridGraphDataset(grid_dataset_val, graph_dataset_val)\n",
    "# graph_grid_dataset_test = GridGraphDataset(grid_dataset_test, graph_dataset_test)\n",
    "batch_size = 12  # 假设批次大小为 2\n",
    "\n",
    "train_loader = DataLoader(graph_grid_dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(graph_grid_dataset_val, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(graph_grid_dataset_test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "for i, (input_tensor_grid, input_tensor_graph, output_tensor_grid, output_tensor_graph, time_grid, time_graph, lan_lon) in enumerate(test_loader):\n",
    "    # print(input_tensor_grid.shape)\n",
    "    # print(\"max: \", torch.max(lan_lon))\n",
    "    # print(\"min: \", torch.min(lan_lon))\n",
    "    has_nan = torch.isnan(input_tensor_graph).any()\n",
    "    # print(has_nan)\n",
    "    print(lan_lon)\n",
    "    \n",
    "    print(input_tensor_graph.shape)\n",
    "    print(output_tensor_graph.shape)\n",
    "    print(input_tensor_grid.shape)\n",
    "    print(output_tensor_grid.shape)\n",
    "    print(time_grid.shape)\n",
    "    print(time_graph.shape)\n",
    "    print(lan_lon.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8d7883-ce3e-4654-b8ed-9cf5043e54de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4pdvGPU Warn(3794:140099667196800:utils.c:228)]: get default cuda 1 from (null)\n",
      "[4pdvGPU Msg(3794:140099667196800:libvgpu.c:902)]: Initialized\n"
     ]
    }
   ],
   "source": [
    "output_model_path = '/home/jovyan/work/spatial-temporal/outputs/0401/models'\n",
    "output_predict_path = '/home/jovyan/work/spatial-temporal/outputs/0401/preds'\n",
    "\n",
    "h, w = 128, 256  # Grid height and width\n",
    "T, T_prime = 6, 6  # Number of time steps for grid and graph\n",
    "C, C_prime = 1, 1  # Number of channels for grid and graph\n",
    "N = 5671\n",
    "feature_dims = 32  # Node feature dimensionality\n",
    "target_t = 6\n",
    "target_v = 1\n",
    "\n",
    "input_dim = 1  # Input dimension for time embeddings\n",
    "patch_size = 16  # Patch size for grid2graph module\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not os.path.exists(output_model_path):\n",
    "    os.mkdir(output_model_path)\n",
    "    print(f\"create folder {output_model_path}\")\n",
    "    \n",
    "if not os.path.exists(output_predict_path):\n",
    "    os.mkdir(output_predict_path)\n",
    "    print(f\"create folder {output_predict_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09df6a01-da15-4060-a446-a54787456ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.graph_grid_model.stg2cm import *\n",
    "\n",
    "h, w = 128, 256  # Grid height and width\n",
    "T, T_prime = 6, 6  # Number of time steps for grid and graph\n",
    "C, C_prime = 1, 1  # Number of channels for grid and graph\n",
    "N = 5671  # Number of graph nodes\n",
    "feature_dims = 32  # Node feature dimensionality\n",
    "input_dim = 1  # Input dimension for time embeddings\n",
    "patch_size = 16  # Patch size for grid2graph module\n",
    "num_epochs = 50\n",
    "learning_rate = 2e-5 \n",
    "target_t_grid = 6\n",
    "target_t_graph = 6\n",
    "target_v = 1\n",
    "\n",
    "\n",
    "model = STG2CM(h,\n",
    "            w,\n",
    "            patch_size,\n",
    "            grid_input_dim = C,\n",
    "            grid_feature_dim = feature_dims,\n",
    "            grid_input_t = T,\n",
    "\n",
    "            graph_nodes=N,\n",
    "            graph_input_dim = C_prime,\n",
    "            graph_feature_dim = feature_dims,\n",
    "            graph_input_t = T_prime,\n",
    "\n",
    "            target_dim_v = target_v,\n",
    "            target_dim_t_grid = target_t_grid,\n",
    "            target_dim_t_graph = target_t_graph)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#scheduler = CyclicLR(optimizer, base_lr=learning_rate, max_lr=1e-3, cycle_momentum=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923f439c-32db-471d-a2f1-bcc60e8de05e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/yyy/spatialtemporal/177ac9f7a3094deb89379f031addeee4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "    api_key=\"xxx\",  # 替换为你的 Comet API Key\n",
    "    project_name=\"spatialtemporal\",\n",
    "    workspace=\"yyy\"  # 替换为你的 Comet 工作区\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873471ef-2a0a-4386-a414-0f16c3b8af7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-08 08:45:56.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mEpoch [1/50]\u001b[0m\n",
      "Training:   0%|          | 0/486 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_data.shape: torch.Size([12, 6, 1, 128, 256])\n",
      "ode x.shape: torch.Size([12, 16, 6, 128, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/486 [00:22<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ode sol.shape: torch.Size([6, 12, 16, 6, 128, 256])\n",
      "ode sol_out.shape: torch.Size([12, 6, 1, 128, 256])\n",
      "grid_data_ode.shape: torch.Size([12, 6, 128, 256, 1])\n",
      "combined_grid.shape: torch.Size([12, 6, 32, 128, 256])\n",
      "graph_attn_output shape  torch.Size([12, 6, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"b (t n) c -> b t n c\".\n Input tensor shape: torch.Size([12, 6, 32]). Additional info: {'t': 6, 'n': 351}.\n Shape mismatch, 6 != 2106",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/einops/einops.py:412\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    411\u001b[0m     recipe \u001b[38;5;241m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_lengths\u001b[38;5;241m=\u001b[39mhashable_axes_lengths)\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _apply_recipe(recipe, tensor, reduction_type\u001b[38;5;241m=\u001b[39mreduction)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EinopsError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/einops/einops.py:235\u001b[0m, in \u001b[0;36m_apply_recipe\u001b[0;34m(recipe, tensor, reduction_type)\u001b[0m\n\u001b[1;32m    233\u001b[0m backend \u001b[38;5;241m=\u001b[39m get_backend(tensor)\n\u001b[1;32m    234\u001b[0m init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 235\u001b[0m     _reconstruct_from_shape(recipe, backend\u001b[38;5;241m.\u001b[39mshape(tensor))\n\u001b[1;32m    236\u001b[0m tensor \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mreshape(tensor, init_shapes)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/einops/einops.py:191\u001b[0m, in \u001b[0;36m_reconstruct_from_shape_uncached\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(length, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(known_product, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m length \u001b[38;5;241m!=\u001b[39m known_product:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape mismatch, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(length, known_product))\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# this is enforced when recipe is created\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# elif len(unknown_axes) > 1:\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m#     raise EinopsError(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mEinopsError\u001b[0m: Shape mismatch, 6 != 2106",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     23\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain_one_epoch_STG2CM()\n\u001b[1;32m     26\u001b[0m     val_loss, val_metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 测试\u001b[39;00m\n",
      "File \u001b[0;32m~/work/spatial-temporal/train.py:66\u001b[0m, in \u001b[0;36mTrainer.train_one_epoch_STG2CM\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(\"把数据放到device上:\", time_1_2-time_1_1)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m time0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 66\u001b[0m predicted_grid, predicted_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(input_tensor_graph, input_tensor_grid, lan_lon, time_graph, time_grid)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# print(predicted_grid)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# print(output_tensor_grid)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# print(predicted_graph)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(output_tensor_graph)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m time1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/spatial-temporal/models/graph_grid_model/stg2cm.py:76\u001b[0m, in \u001b[0;36mSTG2CM.forward\u001b[0;34m(self, graph_data, grid_data, lat_lon_coords, graph_time_indices, grid_time_indices)\u001b[0m\n\u001b[1;32m     73\u001b[0m time3 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# print(\"graph_features\", graph_features)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# print(\"grid2graph time cost: \", time3-time2)\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m graph_features, grid_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_grid_fusion(graph_features, grid_features, graph_time_indices, grid_time_indices)\n\u001b[1;32m     77\u001b[0m time4 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# print(\"graph_features fusion\", graph_features.shape)\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# print(\"grid_features fusion\", grid_features.shape)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# print(\"graph_grid_fusion time cost: \", time4-time3)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/spatial-temporal/models/graph_grid_model/graph_grid_fusion.py:378\u001b[0m, in \u001b[0;36mGraphGridCrossAttnModel.forward\u001b[0;34m(self, graph_features, grid_features, graph_time_indices, grid_time_indices)\u001b[0m\n\u001b[1;32m    375\u001b[0m graph_attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_graph(graph_time_embedded, graph_k, graph_v)  \u001b[38;5;66;03m# (batchsize, t *, d)]\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph_attn_output shape \u001b[39m\u001b[38;5;124m\"\u001b[39m,graph_attn_output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 378\u001b[0m graph_attn_output \u001b[38;5;241m=\u001b[39m rearrange(graph_attn_output, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb (t n) c -> b t n c\u001b[39m\u001b[38;5;124m'\u001b[39m,t\u001b[38;5;241m=\u001b[39mt,n\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# Grid data: (batchsize, t, c, h, w) -> (batchsize, t, h*w*c)\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# print(grid_features.shape)\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# grid_features = rearrange(grid_features, 'b t c h w -> b t (c h w)')\u001b[39;00m\n\u001b[1;32m    383\u001b[0m grid_features_patched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_emb(grid_features)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/einops/einops.py:483\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRearrange can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be applied to an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    482\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m get_backend(tensor[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstack_on_zeroth_dimension(tensor)\n\u001b[0;32m--> 483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(cast(Tensor, tensor), pattern, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrearrange\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/einops/einops.py:420\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    418\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Input is list. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    419\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdditional info: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(axes_lengths)\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n",
      "\u001b[0;31mEinopsError\u001b[0m:  Error while processing rearrange-reduction pattern \"b (t n) c -> b t n c\".\n Input tensor shape: torch.Size([12, 6, 32]). Additional info: {'t': 6, 'n': 351}.\n Shape mismatch, 6 != 2106"
     ]
    }
   ],
   "source": [
    "##### Comet.ml 实验记录\n",
    "experiment.log_parameters({\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"learning_rate\": learning_rate\n",
    "})\n",
    "\n",
    "# 训练器实例化\n",
    "trainer = Trainer(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    output_path=output_model_path,\n",
    "    experiment=experiment\n",
    ")\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    logger.info(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    train_loss = trainer.train_one_epoch_STG2CM()\n",
    "\n",
    "    val_loss, val_metrics = trainer.validate()\n",
    "\n",
    "# 测试\n",
    "test_loss, test_metrics = trainer.test()\n",
    "\n",
    "\n",
    "# 结束实验\n",
    "experiment.end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1bbed-e107-4418-ba27-e14c657b99f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(graph_dataset_train.__len__())\n",
    "print(grid_dataset_train.__len__())\n",
    "len(graph_dataset_train.timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1fce87-8af1-4d6c-b883-d3e04cc1aab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device, save_dir=\"test_outputs\"):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_path = os.path.join(save_dir, f\"test_{timestamp}\")\n",
    "    \n",
    "    # 创建独立目录\n",
    "    grid_dir = os.path.join(save_path, \"grid\")\n",
    "    graph_dir = os.path.join(save_path, \"graph\")\n",
    "    os.makedirs(grid_dir, exist_ok=True)\n",
    "    os.makedirs(graph_dir, exist_ok=True)\n",
    "    \n",
    "    metrics = {\"grid_mse\": 0.0, \"grid_rmse\": 0.0, \"graph_mse\": 0.0, \"graph_rmse\": 0.0, \"total_samples\": 0}\n",
    "    \n",
    "    # 标记是否已保存 lan_lon\n",
    "    lan_lon_saved = False\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_grid, input_graph, target_grid, target_graph, time_grid, time_graph, lan_lon) in enumerate(tqdm(test_loader)):\n",
    "            # 确保所有输入张量在相同设备上\n",
    "            input_grid = input_grid.to(device)\n",
    "            input_graph = input_graph.to(device)\n",
    "            target_grid = target_grid.to(device)\n",
    "            target_graph = target_graph.to(device)\n",
    "            time_grid = time_grid.to(device)      # 时间相关张量转移到设备\n",
    "            time_graph = time_graph.to(device)    # 时间相关张量转移到设备\n",
    "            lan_lon = lan_lon.to(device)          # 经纬度转移到设备\n",
    "            \n",
    "            # 仅保存一次 lan_lon\n",
    "            if not lan_lon_saved:\n",
    "                np.save(os.path.join(save_path, \"lan_lon.npy\"), lan_lon.cpu().numpy())\n",
    "                lan_lon_saved = True\n",
    "            \n",
    "            # 模型推理\n",
    "            pred_grid, pred_graph = model(\n",
    "                input_graph,   # 确保输入顺序与模型定义一致\n",
    "                input_grid,\n",
    "                lan_lon,\n",
    "                time_graph,\n",
    "                time_grid\n",
    "            )\n",
    "            \n",
    "            # 保存Grid和Graph数据\n",
    "            np.save(os.path.join(grid_dir, f\"pred_batch_{batch_idx}.npy\"), pred_grid.cpu().numpy())\n",
    "            np.save(os.path.join(grid_dir, f\"target_batch_{batch_idx}.npy\"), target_grid.cpu().numpy())\n",
    "            np.save(os.path.join(graph_dir, f\"pred_batch_{batch_idx}.npy\"), pred_graph.cpu().numpy())\n",
    "            np.save(os.path.join(graph_dir, f\"target_batch_{batch_idx}.npy\"), target_graph.cpu().numpy())\n",
    "            \n",
    "            # 计算指标\n",
    "            batch_size = input_grid.size(0)\n",
    "            metrics[\"total_samples\"] += batch_size\n",
    "            metrics[\"grid_mse\"] += torch.mean((pred_grid - target_grid)**2).item() * batch_size\n",
    "            metrics[\"graph_mse\"] += torch.mean((pred_graph - target_graph)**2).item() * batch_size\n",
    "    \n",
    "    # 计算RMSE\n",
    "    metrics[\"grid_rmse\"] = np.sqrt(metrics[\"grid_mse\"] / metrics[\"total_samples\"])\n",
    "    metrics[\"graph_rmse\"] = np.sqrt(metrics[\"graph_mse\"] / metrics[\"total_samples\"])\n",
    "    metrics[\"grid_mse\"] /= metrics[\"total_samples\"]\n",
    "    metrics[\"graph_mse\"] /= metrics[\"total_samples\"]\n",
    "    \n",
    "    # 保存指标\n",
    "    with open(os.path.join(save_path, \"metrics.txt\"), \"w\") as f:\n",
    "        f.write(f\"Grid MSE: {metrics['grid_mse']:.4f}\\nGrid RMSE: {metrics['grid_rmse']:.4f}\\n\")\n",
    "        f.write(f\"Graph MSE: {metrics['graph_mse']:.4f}\\nGraph RMSE: {metrics['graph_rmse']:.4f}\\n\")\n",
    "    \n",
    "    print(f\"结果保存至: {save_path}\")\n",
    "    return metrics\n",
    "\n",
    "\n",
    "best_model_path = os.path.join(output_model_path, 'model_epoch=1_RMSE=0.0176.pth')\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "logger.info(f\"Loaded best model from {best_model_path}\")\n",
    "test_metrics = test_model(model, val_loader, device, save_dir=output_predict_path)\n",
    "print(\"\\n最终测试指标:\")\n",
    "print(f\"Grid MSE: {test_metrics['grid_mse']:.4f}\")\n",
    "print(f\"Grid RMSE: {test_metrics['grid_rmse']:.4f}\")\n",
    "print(f\"Graph MSE: {test_metrics['graph_mse']:.4f}\")\n",
    "print(f\"Graph RMSE: {test_metrics['graph_rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e73bf7-005c-49ed-ba4d-aebdb89b7b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "\n",
    "def visualize_grid(grid_dir, batch_id=0, step=1, save_path=\"grid_animation.gif\"):\n",
    "    \"\"\"\n",
    "    生成Grid预测与标签的对比动态图\n",
    "    Args:\n",
    "        grid_dir: Grid数据目录路径\n",
    "        batch_id: 要可视化的Batch编号\n",
    "        step: 时间步间隔\n",
    "        save_path: GIF保存路径\n",
    "    \"\"\"\n",
    "    # 加载数据\n",
    "    pred_path = os.path.join(grid_dir, f\"pred_batch_{batch_id}.npy\")\n",
    "    target_path = os.path.join(grid_dir, f\"target_batch_{batch_id}.npy\")\n",
    "    pred = np.load(pred_path)  # 形状应为 (B, T, C, H, W)\n",
    "    target = np.load(target_path)\n",
    "    \n",
    "    # 检查数据维度\n",
    "    if pred.ndim != 5:\n",
    "        raise ValueError(f\"Grid预测数据维度应为 (B, T, C, H, W)，当前维度为 {pred.shape}\")\n",
    "    \n",
    "    # 取第一个样本和第一个通道\n",
    "    sample_idx = 0\n",
    "    channel_idx = 0\n",
    "    pred = pred[sample_idx, :, channel_idx]  # (T, H, W)\n",
    "    target = target[sample_idx, :, channel_idx]\n",
    "\n",
    "    # 生成帧\n",
    "    frames = []\n",
    "    for t in range(0, pred.shape[0], step):  # 正确遍历时间步维度 T\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # 预测结果\n",
    "        im1 = axes[0].imshow(pred[t], cmap=\"viridis\", vmin=target.min(), vmax=target.max())\n",
    "        axes[0].set_title(\"Prediction\")\n",
    "        plt.colorbar(im1, ax=axes[0])\n",
    "        \n",
    "        # 真实标签\n",
    "        im2 = axes[1].imshow(target[t], cmap=\"viridis\", vmin=target.min(), vmax=target.max())\n",
    "        axes[1].set_title(\"Ground Truth\")\n",
    "        plt.colorbar(im2, ax=axes[1])\n",
    "        \n",
    "        # 计算指标\n",
    "        mse = np.mean((pred[t] - target[t]) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # 添加标题\n",
    "        plt.suptitle(f\"Grid Predictions vs Targets (t={t})\\nMSE: {mse:.4f}, RMSE: {rmse:.4f}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 转为图像帧\n",
    "        fig.canvas.draw()\n",
    "        frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "        frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        frames.append(frame)\n",
    "        plt.close()\n",
    "    \n",
    "    # 保存GIF\n",
    "    imageio.mimsave(save_path, frames, duration=500)\n",
    "    print(f\"Grid动态图已保存至: {save_path} (共{len(frames)}帧)\")\n",
    "    \n",
    "def visualize_graph(graph_dir, lan_lon_path, batch_id=0, step=1, save_path=\"graph_animation.gif\"):\n",
    "    \"\"\"\n",
    "    生成Graph预测与标签的对比动态图\n",
    "    Args:\n",
    "        graph_dir: Graph数据目录路径\n",
    "        lan_lon_path: 经纬度文件路径\n",
    "        batch_id: 要可视化的Batch编号\n",
    "        step: 时间步间隔\n",
    "        save_path: GIF保存路径\n",
    "    \"\"\"\n",
    "    # 加载数据\n",
    "    pred_path = os.path.join(graph_dir, f\"pred_batch_{batch_id}.npy\")\n",
    "    target_path = os.path.join(graph_dir, f\"target_batch_{batch_id}.npy\")\n",
    "    pred = np.load(pred_path)  # 形状应为 (B, T, N, C)\n",
    "    target = np.load(target_path)\n",
    "    lan_lon = np.load(lan_lon_path)  # 形状应为 (B, N, 2)\n",
    "    \n",
    "    # 检查数据维度\n",
    "    if pred.ndim != 4:\n",
    "        raise ValueError(f\"Graph预测数据维度应为 (B, T, N, C)，当前维度为 {55555pred.shape}\")\n",
    "    \n",
    "    # 取第一个样本和第一个通道\n",
    "    sample_idx = 0\n",
    "    channel_idx = 0\n",
    "    pred = pred[sample_idx, :, :, channel_idx]  # (T, N)\n",
    "    target = target[sample_idx, :, :, channel_idx]\n",
    "    coordinates = lan_lon[sample_idx]  # (N, 2)\n",
    "\n",
    "    # 生成帧\n",
    "    frames = []\n",
    "    for t in range(0, pred.shape[0], step):  # 正确遍历时间步维度 T\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # 预测结果\n",
    "        sc1 = axes[0].scatter(\n",
    "            coordinates[:, 0], coordinates[:, 1], \n",
    "            c=pred[t], cmap=\"coolwarm\", s=50, \n",
    "            vmin=target.min(), vmax=target.max()\n",
    "        )\n",
    "        axes[0].set_title(\"Prediction\")\n",
    "        plt.colorbar(sc1, ax=axes[0])\n",
    "        \n",
    "        # 真实标签\n",
    "        sc2 = axes[1].scatter(\n",
    "            coordinates[:, 0], coordinates[:, 1], \n",
    "            c=target[t], cmap=\"coolwarm\", s=50, \n",
    "            vmin=target.min(), vmax=target.max()\n",
    "        )\n",
    "        axes[1].set_title(\"Ground Truth\")\n",
    "        plt.colorbar(sc2, ax=axes[1])\n",
    "        \n",
    "        # 计算指标\n",
    "        mse = np.mean((pred[t] - target[t]) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # 添加标题\n",
    "        plt.suptitle(f\"Graph Predictions vs Targets (t={t})\\nMSE: {mse:.4f}, RMSE: {rmse:.4f}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 转为图像帧\n",
    "        fig.canvas.draw()\n",
    "        frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "        frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        frames.append(frame)\n",
    "        plt.close()\n",
    "    \n",
    "    # 保存GIF\n",
    "    imageio.mimsave(save_path, frames, duration=500)\n",
    "    print(f\"Graph动态图已保存至: {save_path} (共{len(frames)}帧)\")\n",
    "# 1. 加载测试结果（根据你的保存路径调整）\n",
    "# test_output_dir = \"/home/jovyan/work/spatial-temporal/outputs/0126/preds/test_20250325_154036\"\n",
    "test_dir = \"/home/jovyan/work/spatial-temporal/outputs/0126/preds/test_20250325_162634\"\n",
    "\n",
    "# 生成Grid动态图（第0个Batch）\n",
    "visualize_grid(\n",
    "    grid_dir=os.path.join(test_dir, \"grid\"),\n",
    "    batch_id=0,\n",
    "    step=2,\n",
    "    save_path=os.path.join(test_dir, \"grid_animation.gif\")\n",
    ")\n",
    "\n",
    "# 生成Graph动态图（第0个Batch）\n",
    "visualize_graph(\n",
    "    graph_dir=os.path.join(test_dir, \"graph\"),\n",
    "    lan_lon_path=os.path.join(test_dir, \"lan_lon.npy\"),\n",
    "    batch_id=0,\n",
    "    step=2,\n",
    "    save_path=os.path.join(test_dir, \"graph_animation.gif\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46a19e-4697-4d2d-9430-2aec6d0ae546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "def calculate_errors(pred, label):\n",
    "    # 均方误差 (Mean Squared Error)\n",
    "    mse = np.mean((pred - label) ** 2)\n",
    "    \n",
    "    # 均方根误差 (Root Mean Squared Error)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # 平均绝对误差 (Mean Absolute Error)\n",
    "    mae = np.mean(np.abs(pred - label))\n",
    "    \n",
    "    # 区域平均误差 (Zonal Mean Error)\n",
    "    zonal_mean_error = np.mean(np.abs(pred - label), axis=1).mean()\n",
    "    \n",
    "    # 技能评分 (Anomaly Correlation Coefficient, ACC)\n",
    "    mean_pred = np.mean(pred)\n",
    "    mean_label = np.mean(label)\n",
    "    cov_pred_label = np.mean((pred - mean_pred) * (label - mean_label))\n",
    "    std_pred = np.std(pred)\n",
    "    std_label = np.std(label)\n",
    "    \n",
    "    if std_pred > 0 and std_label > 0:\n",
    "        skill_score = cov_pred_label / (std_pred * std_label)\n",
    "    else:\n",
    "        skill_score = None\n",
    "    \n",
    "    return {\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"Skill Score\": skill_score,\n",
    "        \"Zonal Mean Error\": zonal_mean_error\n",
    "    }\n",
    "\n",
    "# 加载预测结果和真实标签\n",
    "prediction_file = os.path.join(output_predict_path, 'predictions.nc')\n",
    "label_file = os.path.join(output_predict_path, 'labels.nc')\n",
    "\n",
    "predictions = xr.open_dataset(prediction_file)\n",
    "label_data = xr.open_dataset(label_file)\n",
    "\n",
    "# 检查数据集结构\n",
    "print(\"Predictions dataset:\")\n",
    "print(predictions)\n",
    "print(\"\\nLabels dataset:\")\n",
    "print(label_data)\n",
    "\n",
    "# 确保有时间坐标\n",
    "if 'time' not in predictions.coords or 'time' not in label_data.coords:\n",
    "    raise KeyError(\"Datasets do not contain 'time' coordinates.\")\n",
    "\n",
    "# 假设 x 和 y 坐标不存在，则生成默认的网格坐标\n",
    "height, width = predictions[\"prediction\"].shape[-2:]\n",
    "x_coords = np.linspace(-180, 180, width)  # 示例经度范围\n",
    "y_coords = np.linspace(-90, 90, height)   # 示例纬度范围\n",
    "\n",
    "gif_filename = os.path.join(output_predict_path, \"predictions_with_errors.gif\")\n",
    "\n",
    "step = 100  # 设置步长以减少帧数\n",
    "print(f\"Total frames: {len(predictions['time'])}, Displaying every {step} frames.\")\n",
    "\n",
    "frames = []\n",
    "for i in tqdm(range(0, len(predictions[\"time\"]), step), desc=\"Generating frames\"):\n",
    "    # 获取当前时间步的预测值和真实值\n",
    "    pred_t2m = predictions[\"prediction\"].isel(time=i).values.squeeze()\n",
    "    label_t2m = label_data[\"label\"].isel(time=i).values.squeeze()\n",
    "\n",
    "    # 计算误差指标\n",
    "    errors = calculate_errors(pred_t2m, label_t2m)\n",
    "\n",
    "    # 绘图\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    fig.suptitle(f\"Time: {predictions['time'][i].values}\\n\" +\n",
    "                 f\"MSE: {errors['MSE']:.4f}, RMSE: {errors['RMSE']:.4f}, MAE: {errors['MAE']:.4f}, \" +\n",
    "                 (f\"Skill Score: {errors['Skill Score']:.4f}\" if errors['Skill Score'] is not None else \"\") +\n",
    "                 f\", Zonal Mean Error: {errors['Zonal Mean Error']:.4f}\")\n",
    "\n",
    "    # 显示预测结果\n",
    "    ax[0].set_title(\"Prediction\")\n",
    "    im = ax[0].pcolormesh(x_coords, y_coords, pred_t2m, shading=\"auto\", cmap=\"coolwarm\")\n",
    "    plt.colorbar(im, ax=ax[0], label=\"Temperature (K)\")\n",
    "    ax[0].set_xlabel(\"Longitude\")\n",
    "    ax[0].set_ylabel(\"Latitude\")\n",
    "\n",
    "    # 显示真实值\n",
    "    ax[1].set_title(\"Ground Truth\")\n",
    "    im = ax[1].pcolormesh(x_coords, y_coords, label_t2m, shading=\"auto\", cmap=\"coolwarm\")\n",
    "    plt.colorbar(im, ax=ax[1], label=\"Temperature (K)\")\n",
    "    ax[1].set_xlabel(\"Longitude\")\n",
    "    ax[1].set_ylabel(\"Latitude\")\n",
    "\n",
    "    # 将 matplotlib Figure 转换为 Pillow Image\n",
    "    canvas = FigureCanvas(fig)\n",
    "    canvas.draw()\n",
    "    image = Image.frombytes('RGB', canvas.get_width_height(), canvas.tostring_rgb())\n",
    "    frames.append(image)\n",
    "    plt.close(fig)  # 关闭以节省内存\n",
    "\n",
    "# 保存为 GIF\n",
    "frames[0].save(\n",
    "    gif_filename,\n",
    "    save_all=True,\n",
    "    append_images=frames[1:],\n",
    "    duration=300,\n",
    "    loop=0,\n",
    ")\n",
    "\n",
    "print(f\"GIF saved successfully as '{gif_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e5f7f-1ae7-4750-a4ec-955c539376c3",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
